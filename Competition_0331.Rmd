---

title: "TSA Forecasting Competition"
author: "Yu Hai and Jack Mitchell"
date: "2022/3/31"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=80), tidy=FALSE) 
```

```{r package, message=FALSE, warning=FALSE}
library(readxl)
library(lubridate)
library(ggplot2)
library(forecast)
library(Kendall)
library(tseries)
library(outliers)
library(tidyverse)
library(smooth)
library(zoo)
library(kableExtra)
#install.packages("writexl")
library(writexl)

```

```{r import data}
load_data<-read_excel(path="./Data/load.xlsx") #import load data
head(load_data)

humidity_data<-read_excel(path="./Data/relative_humidity.xlsx") #import humidity data
head(humidity_data)

temperature_data<-read_excel(path="./Data/temperature.xlsx") #import temp data
head(temperature_data)
```

```{r}
load_data$load_daily_avg = rowMeans(load_data[,c(3:26)]) #calculate avg daily load
head(load_data)
ts_load_daily_avg<-msts(load_data$load_daily_avg,seasonal.periods =c(7,365.25),start=c(2005,01,01)) #convert to time series


humidity_data_daily <- humidity_data %>%  #avg daily humidity data
  mutate( Year = year(date),
          Month = month(date),
          Day = day(date)) %>%
  select( date, Year, Month, Day, hr, rh_ws1) %>%
  group_by(date,Year,Month,Day) %>%
  summarise(daily_mean_humidity = mean(rh_ws1))

temperature_data_daily <- temperature_data %>% #avg daily temperature data
  mutate( Year = year(date),
          Month = month(date),
          Day = day(date)) %>%
  select( date, Year, Month, Day, hr, t_ws1) %>%
  group_by(date,Year,Month,Day) %>%
  summarise(daily_mean_temp = mean(t_ws1)) 
```

```{r}
n_for=365 # days in a year
ts_load_daily_avg_train<-subset(ts_load_daily_avg,end=length(ts_load_daily_avg)-n_for) #create training subset
ts_load_daily_avg_test<-subset(ts_load_daily_avg,start=length(ts_load_daily_avg)-n_for) #create testing subset 
ts_load_daily_avg_train %>% mstl() %>%
autoplot() #decompose training subset
autoplot(ts_load_daily_avg_train) #time series plot of training subset
```
```{r}
#STL+ETS
ts_load_daily_avg_train %>% stlf(h=365) %>% autoplot()

ETS_fit <-  stlf(ts_load_daily_avg_train,h=365)
autoplot(ts_load_daily_avg) +
  autolayer(ETS_fit, series="STL + ETS",PI=FALSE) +
  ylab("Daily Load")
```

```{r}
#Arima model with fourier terms
ARIMA_Four_fit <- auto.arima(ts_load_daily_avg_train, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_load_daily_avg_train, 
                                          K=c(2,12))
                             )
ARIMA_Four_for <- forecast::forecast(ARIMA_Four_fit,
                           xreg=fourier(ts_load_daily_avg_train,
                                        K=c(2,12),
                                        h=365),
                           h=365
                           ) 

#Plot foresting results
autoplot(ARIMA_Four_for) + ylab("Daily Load")

#Plot model + observed data
autoplot(ts_load_daily_avg) +
  autolayer(ARIMA_Four_for, series="ARIMA_FOURIER",PI=FALSE) +
  ylab("Daily Load")
```


```{r}
# TBATS can take time to fit
TBATS_fit <- tbats(ts_load_daily_avg_train)

TBATS_for <- forecast::forecast(TBATS_fit, h=365)

#Plot foresting results
autoplot(TBATS_for) +
  ylab("Daily Load") 

#Plot model + observed data
autoplot(ts_load_daily_avg) +
  autolayer(TBATS_for, series="TBATS",PI=FALSE)+
  ylab("Daily Load") 
```

```{r}
#You can play with the different values for p and P, you can also use xreg with Fourier term to model the multiple seasonality

#NN_fit <- nnetar(ts_act_power_daily_train,p=1,P=1)
NN_fit <- nnetar(ts_load_daily_avg_train,p=1,P=0,xreg=fourier(ts_load_daily_avg_train, K=c(2,12)))

#NN_for <- forecast(NN_fit, h=365) 
NN_for <- forecast::forecast(NN_fit, h=365,xreg=fourier(ts_load_daily_avg_train, 
                                          K=c(2,12),h=365))

#Plot foresting results
autoplot(NN_for) +
  ylab("Daily Load") 

#Plot model + observed data
autoplot(ts_load_daily_avg) +
  autolayer(NN_for, series="Neural Network",PI=FALSE)+
  ylab("Daily Load") 
```

```{r}
#Seasonal naive model
SNAIVE <- snaive(ts_load_daily_avg_train, h=365)
autoplot(SNAIVE) +
  ylab("Daily Load") 

#Plot model + observed data
autoplot(ts_load_daily_avg) +
  autolayer(SNAIVE, series="Seasonal Naive",PI=FALSE)+
  ylab("Daily Load")
```

```{r}
#Auto arima model
ARIMA_autofit <- auto.arima(ts_load_daily_avg_train, max.D = 0, max.P = 0, max.Q = 0)
ARIMA_forecast <- forecast::forecast(object = ARIMA_autofit, h = 365)
autoplot(ARIMA_forecast) +
  ylab("Daily Load")

#Plot model + observed data
autoplot(ts_load_daily_avg) +
  autolayer(ARIMA_forecast, series="Auto Arima",PI=FALSE)+
  ylab("Daily Load")
```
```{r}
ARIMA_temp_autofit <- auto.arima(ts_load_daily_avg_train, max.D = 0, max.P = 0, max.Q = 0,xreg=ts_temp_data_daily)
ARIMA_temp_forecast <- forecast::forecast(object = ARIMA_temp_autofit, h = 365)
autoplot(ARIMA_temp_forecast) +
  ylab("Daily Load")
```
```{r}
temperature_data_daily
ts_temp_data_daily <- ts(temperature_data_daily$daily_mean_temp,frequency=365,start=c(2005,01,01), end = c(2007,09,27)) 
ts_temp_data_daily2 <- ts(temperature_data_daily$daily_mean_temp,frequency=365,start=c(2005,01))
plot(ts_temp_data_daily)
plot(ts_temp_data_daily2)
humidity_data_daily
```


```{r accuracy scores}
#Model 1: STL + ETS
ETS_scores <- accuracy(ETS_fit$mean,ts_load_daily_avg_test)  

#Model 2: ARIMA + Fourier 
ARIMA_scores <- accuracy(ARIMA_Four_for$mean,ts_load_daily_avg_test)

# Model 3:  TBATS 
TBATS_scores <- accuracy(TBATS_for$mean,ts_load_daily_avg_test)

# Model 4:  Neural Network 
NN_scores <- accuracy(NN_for$mean,ts_load_daily_avg_test)

# Model 5: Seasonal Naive 
SNAIVE_scores <- accuracy(SNAIVE$mean,ts_load_daily_avg_test)

#Model 6: Auto Arima
AutoArima_scores <- accuracy(ARIMA_forecast$mean,ts_load_daily_avg_test)
```


```{r summarize scores}
scores <- as.data.frame(
  rbind(ETS_scores, ARIMA_scores, TBATS_scores, NN_scores, SNAIVE_scores,AutoArima_scores)
  )
row.names(scores) <- c("STL+ETS", "ARIMA+Fourier","TBATS","NN", "SNAIVE", "Auto Arima")

#choose model with lowest RMSE
best_model_index <- which.min(scores[,"RMSE"])
cat("The best model by RMSE is:", row.names(scores[best_model_index,]))  

kbl(scores, 
      caption = "Forecast Accuracy for Daily Active Power",
      digits = array(5,ncol(scores))) %>%
  kable_styling(full_width = FALSE, position = "center", latex_options = "hold_position") %>%
  #highlight model with lowest RMSE
  kable_styling(latex_options="striped", stripe_index = which.min(scores[,"RMSE"]))
```

```{r Jan 2011 Forecasts}
#Arima model with fourier terms
ARIMA_Four_fit2 <- auto.arima(ts_load_daily_avg, 
                             seasonal=FALSE, 
                             lambda=0,
                             xreg=fourier(ts_load_daily_avg, 
                                          K=c(2,12))
                             )
ARIMA_Four_for2 <- forecast::forecast(ARIMA_Four_fit2,
                           xreg=fourier(ts_load_daily_avg,
                                        K=c(2,12),
                                        h=31),
                           h=31
                           ) 

#Plot forecasting results
autoplot(ARIMA_Four_for2) + ylab("Daily Load")

#Convert forecasting results to dataframe
Forecast1 <- data.frame(load = ARIMA_Four_for2[["mean"]])
```


```{r export results to excel}
write.csv(Forecast1, "~\\ENVIRON 790\\ENV790_TimeSeriesAnalysis_Sp2022\\Competition\\Output\\Forecast1.csv")

```

